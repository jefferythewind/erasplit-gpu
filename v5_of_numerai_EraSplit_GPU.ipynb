{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
      ],
      "metadata": {
        "id": "sgmZfKuSiOLK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numerapi"
      ],
      "metadata": {
        "id": "R2aJulrGp4nt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9bcb694-186e-47df-baf1-1c5f4e829151"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numerapi in /usr/local/lib/python3.11/dist-packages (2.20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from numerapi) (2.32.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from numerapi) (2025.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from numerapi) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.11/dist-packages (from numerapi) (4.67.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from numerapi) (8.1.8)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from numerapi) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.0->numerapi) (2.0.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.0->numerapi) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->numerapi) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->numerapi) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->numerapi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->numerapi) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->numerapi) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7CaTqffn03-",
        "outputId": "0ad1847d-f2f5-4e17-e44a-d0d0a5634c8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/erasplit-gpu/\")"
      ],
      "metadata": {
        "id": "tEdf7KzIfq8h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN = False"
      ],
      "metadata": {
        "id": "-Z4X0gdKp2lc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numerapi\n",
        "import json\n",
        "\n",
        "\n",
        "napi = numerapi.NumerAPI()\n",
        "# list the datasets and available versions\n",
        "all_datasets = napi.list_datasets()\n",
        "dataset_versions = list(set(d.split('/')[0] for d in all_datasets))\n",
        "print(\"Available versions:\\n\", dataset_versions)\n",
        "\n",
        "# Set data version to one of the latest datasets\n",
        "DATA_VERSION = \"v5.0\"\n",
        "\n",
        "# Print all files available for download for our version\n",
        "current_version_files = [f for f in all_datasets if f.startswith(DATA_VERSION)]\n",
        "print(\"Available\", DATA_VERSION, \"files:\\n\", current_version_files)\n",
        "\n",
        "\n",
        "# download the feature metadata file\n",
        "napi.download_dataset(f\"{DATA_VERSION}/features.json\")\n",
        "\n",
        "# read the metadata and display\n",
        "feature_metadata = json.load(open(f\"{DATA_VERSION}/features.json\"))\n",
        "for metadata in feature_metadata:\n",
        "  print(metadata, len(feature_metadata[metadata]))\n",
        "\n",
        "feature_sets = feature_metadata[\"feature_sets\"]\n",
        "for feature_set in [\"small\", \"medium\", \"all\"]:\n",
        "  print(feature_set, len(feature_sets[feature_set]))"
      ],
      "metadata": {
        "id": "y49t9zY7p5-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9466bcdc-1855-48f5-eb76-7455412e8f8a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available versions:\n",
            " ['v5.0']\n",
            "Available v5.0 files:\n",
            " ['v5.0/features.json', 'v5.0/live.parquet', 'v5.0/live_benchmark_models.parquet', 'v5.0/live_example_preds.csv', 'v5.0/live_example_preds.parquet', 'v5.0/meta_model.parquet', 'v5.0/train.parquet', 'v5.0/train_benchmark_models.parquet', 'v5.0/validation.parquet', 'v5.0/validation_benchmark_models.parquet', 'v5.0/validation_example_preds.csv', 'v5.0/validation_example_preds.parquet']\n",
            "feature_sets 17\n",
            "targets 37\n",
            "small 42\n",
            "medium 705\n",
            "all 2376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define our feature set from your metadata\n",
        "feature_set = feature_sets[\"all\"]\n",
        "\n",
        "# Define our target columns (for a multi-target approach)\n",
        "# Assumes feature_metadata[\"targets\"] exists and holds a list of target column names\n",
        "#targets = feature_metadata[\"targets\"]\n",
        "\n",
        "targets = [\n",
        "    #\"target_nomi_v4_20\", # until V16\n",
        "    \"target_teager2b_20\", # new from V17\n",
        "    #\"target_jerome_v4_60\", # until V16\n",
        "    \"target_teager2b_60\", # new from V17\n",
        "    #\"target_jeremy_v4_60\", # until V16\n",
        "    \"target_rowan_20\",\n",
        "    \"target_ralph_20\",\n",
        "    \"target_tyler_20\",\n",
        "    \"target_victor_20\",\n",
        "    #\"target_waldo_v4_20\", # until V16\n",
        "    \"target_claudia_20\", # new from V17\n",
        "    \"target_cyrusd_20\"   # adding latest primary target from V16\n",
        "]\n",
        "\n",
        "targets = ['target']"
      ],
      "metadata": {
        "id": "11243C_EqETe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the training data (if not already downloaded)\n",
        "napi.download_dataset(f\"{DATA_VERSION}/train.parquet\" if TRAIN else f\"{DATA_VERSION}/live.parquet\")\n",
        "\n",
        "COLUMNS = [\"era\"] + feature_set + targets if TRAIN else [\"era\"] + feature_set\n",
        "# Load training data\n",
        "# We're loading the \"era\" column, all target columns, and all features\n",
        "train = pd.read_parquet(\n",
        "    f\"{DATA_VERSION}/train.parquet\" if TRAIN else f\"{DATA_VERSION}/live.parquet\",\n",
        "    columns=COLUMNS\n",
        ")\n"
      ],
      "metadata": {
        "id": "aDAZko3EP69q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "epiHs_0G3_cd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ~/.cache/torch_extensions\n"
      ],
      "metadata": {
        "id": "-jnuzqzTmuMl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.cpp_extension import load\n",
        "import os\n",
        "if TRAIN:\n",
        "  # Optional, but recommended: narrow architecture to reduce compile time\n",
        "  os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"8.0\"\n",
        "  PATH = '/content/erasplit-gpu/histogram_ext/'\n",
        "  histogram_ext = load(\n",
        "      name='histogram_ext',\n",
        "      sources=[\n",
        "          PATH + 'histogram.cpp',\n",
        "          PATH + 'best_split_kernel.cu',\n",
        "          PATH + 'histogram_kernel.cu'\n",
        "      ],\n",
        "      extra_cuda_cflags=['-O3', '-gencode=arch=compute_80,code=sm_80', '-DTORCH_USE_CUDA_DSA'],\n",
        "      extra_cflags=['-O3'],\n",
        "      verbose=True  # <-- this shows build logs inline\n",
        "  )\n"
      ],
      "metadata": {
        "id": "vxWkN2GanVjt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WlJ0bkwnYFHa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from tqdm import tqdm\n",
        "from typing import List  # Needed for TorchScript list type annotation\n",
        "\n",
        "# TorchScript function for a single tree traversal.\n",
        "@torch.jit.script\n",
        "def _predict_tree(flat_tree: torch.Tensor, X_batch: torch.Tensor, bin_edges: torch.Tensor, max_depth: int) -> torch.Tensor:\n",
        "    N = X_batch.shape[0]\n",
        "    node_indices = torch.zeros(N, dtype=torch.long, device=X_batch.device)\n",
        "\n",
        "    # Unpack flat_tree columns.\n",
        "    is_leaf = flat_tree[:, 0] > 0       # [num_nodes]\n",
        "    features = flat_tree[:, 1].long()   # [num_nodes]\n",
        "    thresholds = flat_tree[:, 2]        # [num_nodes]\n",
        "    lefts = flat_tree[:, 3].long()      # [num_nodes]\n",
        "    rights = flat_tree[:, 4].long()     # [num_nodes]\n",
        "    values = flat_tree[:, 5]            # [num_nodes]\n",
        "\n",
        "    for _ in range(max_depth + 1):\n",
        "        leaf_mask = is_leaf[node_indices]\n",
        "        if leaf_mask.all():\n",
        "            break\n",
        "\n",
        "        active_idx = torch.nonzero(~leaf_mask).squeeze(1)\n",
        "        cur_nodes = node_indices[active_idx]\n",
        "        cur_features = features[cur_nodes]\n",
        "        cur_thresholds = thresholds[cur_nodes]\n",
        "\n",
        "        # For each active sample, get the feature value.\n",
        "        x = X_batch[active_idx].gather(1, cur_features.unsqueeze(1)).squeeze(1)\n",
        "        boundaries = bin_edges[cur_features]\n",
        "        bin_idx = (x.unsqueeze(1) > boundaries).sum(dim=1)\n",
        "        next_nodes = torch.where(bin_idx <= cur_thresholds, lefts[cur_nodes], rights[cur_nodes])\n",
        "        node_indices[active_idx] = next_nodes\n",
        "\n",
        "    return values[node_indices]\n",
        "\n",
        "# TorchScript function to predict the forest in a loop over trees.\n",
        "@torch.jit.script\n",
        "def _predict_forest(flat_forests: List[torch.Tensor], X_batch: torch.Tensor, bin_edges: torch.Tensor, max_depth: int, learning_rate: float, base_prediction: float) -> torch.Tensor:\n",
        "    N = X_batch.size(0)\n",
        "    preds = torch.full((N,), base_prediction, device=X_batch.device, dtype=torch.float32)\n",
        "    for i in range(len(flat_forests)):\n",
        "         preds = preds + learning_rate * _predict_tree(flat_forests[i], X_batch, bin_edges, max_depth)\n",
        "    return preds\n",
        "\n",
        "import torch\n",
        "from typing import Tuple\n",
        "\n",
        "@torch.jit.script\n",
        "def _predict_forest_vectorized(\n",
        "    flat_forests: torch.Tensor,  # shape: (n_trees, max_nodes, 6)\n",
        "    X_batch: torch.Tensor,       # shape: (N, F)\n",
        "    bin_edges: torch.Tensor,     # shape: (F, num_bins)\n",
        "    max_depth: int,\n",
        "    learning_rate: float,\n",
        "    base_prediction: float\n",
        ") -> torch.Tensor:\n",
        "    n_trees = flat_forests.shape[0]\n",
        "    N = X_batch.shape[0]\n",
        "\n",
        "    # Initialize node indices for every tree and every sample.\n",
        "    node_indices = torch.zeros((n_trees, N), dtype=torch.long, device=X_batch.device)\n",
        "\n",
        "    # Pre-extract the tree info (each flat tree row has 6 columns):\n",
        "    # column 0: is_leaf flag, column 1: feature, column 2: threshold,\n",
        "    # column 3: left child, column 4: right child, column 5: value.\n",
        "    is_leaf = flat_forests[:, :, 0] > 0         # (n_trees, max_nodes)\n",
        "    features = flat_forests[:, :, 1].long()       # (n_trees, max_nodes)\n",
        "    thresholds = flat_forests[:, :, 2]            # (n_trees, max_nodes)\n",
        "    lefts = flat_forests[:, :, 3].long()          # (n_trees, max_nodes)\n",
        "    rights = flat_forests[:, :, 4].long()         # (n_trees, max_nodes)\n",
        "    values = flat_forests[:, :, 5]                # (n_trees, max_nodes)\n",
        "\n",
        "    # Expand X_batch so that we have one copy per tree.\n",
        "    X_exp = X_batch.unsqueeze(0).expand(n_trees, -1, -1)  # shape: (n_trees, N, F)\n",
        "\n",
        "    for _ in range(max_depth + 1):\n",
        "        # For each tree and sample, check if the current node is a leaf.\n",
        "        current_leaf = torch.gather(is_leaf, 1, node_indices)\n",
        "        # If all are leaves, break out.\n",
        "        if current_leaf.all():\n",
        "            break\n",
        "\n",
        "        # For every (tree, sample), get the feature index used at the current node.\n",
        "        cur_features = torch.gather(features, 1, node_indices)  # shape: (n_trees, N)\n",
        "\n",
        "        # Now, for each (tree, sample), grab the feature value from X.\n",
        "        # We do this by treating cur_features as column indices.\n",
        "        # The gathered x will have shape (n_trees, N)\n",
        "        x = X_exp.gather(2, cur_features.unsqueeze(2)).squeeze(2)\n",
        "\n",
        "        # Get the corresponding bin edges for each (tree, sample).\n",
        "        # Here bin_edges is indexed by feature. The resulting shape is (n_trees, N, num_bins)\n",
        "        boundaries = bin_edges[cur_features]\n",
        "\n",
        "        # Compute the bin index by comparing x to the boundaries.\n",
        "        # (x.unsqueeze(2) > boundaries) creates a boolean tensor which we sum along dim=2.\n",
        "        bin_idx = (x.unsqueeze(2) > boundaries).sum(dim=2)\n",
        "\n",
        "        # Get the threshold, left, and right child values for the current node.\n",
        "        cur_thresholds = torch.gather(thresholds, 1, node_indices)\n",
        "        cur_lefts = torch.gather(lefts, 1, node_indices)\n",
        "        cur_rights = torch.gather(rights, 1, node_indices)\n",
        "\n",
        "        # Decide next node index for each (tree, sample).\n",
        "        next_node = torch.where(bin_idx <= cur_thresholds, cur_lefts, cur_rights)\n",
        "\n",
        "        # Only update those samples that are not at a leaf.\n",
        "        node_indices = torch.where(current_leaf, node_indices, next_node)\n",
        "\n",
        "    # Now, gather the leaf values from all trees.\n",
        "    final_values = torch.gather(values, 1, node_indices)  # shape: (n_trees, N)\n",
        "\n",
        "    # Sum over trees (with learning rate) and add base prediction.\n",
        "    preds = base_prediction + learning_rate * final_values.sum(dim=0)\n",
        "    return preds\n",
        "\n",
        "\n",
        "class ErasplitGBDT(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, num_bins=10, max_depth=3, learning_rate=0.1, n_estimators=100):\n",
        "        self.num_bins = num_bins\n",
        "        self.max_depth = max_depth\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_estimators = n_estimators\n",
        "        self.forest = None\n",
        "        self.flat_forest = None  # To store flattened trees.\n",
        "        self.bin_edges = None\n",
        "        self.base_prediction = None\n",
        "        self.unique_eras = None\n",
        "        self.device = \"cuda\"\n",
        "        self.gradients = None\n",
        "        self.root_node_indices = None\n",
        "        self.bin_indices = None\n",
        "        self.Y_gpu = None\n",
        "        self.num_features = None\n",
        "        self.num_samples = None\n",
        "        self.out_feature = torch.zeros(1, device=self.device, dtype=torch.int32)\n",
        "        self.out_bin = torch.zeros(1, device=self.device, dtype=torch.int32)\n",
        "\n",
        "    def fit(self, X, y, era_id):\n",
        "        self.bin_indices, era_indices, self.bin_edges, self.unique_eras, self.Y_gpu = self.preprocess_gpu_data(X, y, era_id)\n",
        "        self.gradients = torch.zeros_like(self.Y_gpu)\n",
        "        self.root_node_indices = torch.arange(self.num_samples, device=self.device)\n",
        "        self.base_prediction = self.Y_gpu.mean().item()\n",
        "        self.gradients += self.base_prediction  # Initialize with mean.\n",
        "        self.forest = self.grow_forest()\n",
        "        # Pre-flatten trees for fast inference.\n",
        "        self.flat_forest = [self.flatten_tree(tree) for tree in self.forest]\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_tensor = torch.from_numpy(X).to(torch.int8).to(self.device)\n",
        "        batch_size = 10_000  # Adjust based on your GPU memory.\n",
        "        preds = []\n",
        "        # First, flatten each tree.\n",
        "        flat_trees = [self.flatten_tree(tree) for tree in self.forest]\n",
        "\n",
        "        # Determine the maximum number of nodes among all trees.\n",
        "        max_nodes = max(tree.shape[0] for tree in flat_trees)\n",
        "\n",
        "        # Pad each tree to have the same number of nodes.\n",
        "        padded_trees = []\n",
        "        for tree in flat_trees:\n",
        "            pad_size = max_nodes - tree.shape[0]\n",
        "            if pad_size > 0:\n",
        "                # Pad with zeros (or a dummy leaf node that won't be used)\n",
        "                padding = torch.zeros((pad_size, tree.shape[1]), device=tree.device, dtype=tree.dtype)\n",
        "                padded_tree = torch.cat([tree, padding], dim=0)\n",
        "            else:\n",
        "                padded_tree = tree\n",
        "            padded_trees.append(padded_tree)\n",
        "\n",
        "        # Stack the padded trees into one tensor of shape (n_trees, max_nodes, 6).\n",
        "        flat_forests_ts = torch.stack(padded_trees, dim=0)\n",
        "\n",
        "        # Assume self.flat_forest_tensor is created at fit time.\n",
        "        for batch_start in tqdm(range(0, X_tensor.shape[0], batch_size), desc=\"Predicting batches\"):\n",
        "            batch_end = min(batch_start + batch_size, X_tensor.shape[0])\n",
        "            X_batch = X_tensor[batch_start:batch_end]\n",
        "            preds.append(_predict_forest_vectorized(flat_forests_ts, X_batch, self.bin_edges,\n",
        "                                                      self.max_depth, self.learning_rate, self.base_prediction))\n",
        "        preds = torch.cat(preds, dim=0)\n",
        "        return preds.cpu().numpy()\n",
        "\n",
        "\n",
        "    def compute_quantile_bins(self, X, num_bins):\n",
        "        N, F = X.shape\n",
        "        bin_edges_list = []\n",
        "        for f in tqdm(range(F), desc=\"Computing bin edges\", leave=False):\n",
        "            feature = X[:, f]\n",
        "            unique_vals = torch.unique(feature)\n",
        "            if unique_vals.numel() == num_bins and torch.all((unique_vals[1:] - unique_vals[:-1]) == 1):\n",
        "                edges = (unique_vals[:-1] + unique_vals[1:]) / 2.0\n",
        "            elif unique_vals.numel() < num_bins:\n",
        "                min_val = unique_vals.min()\n",
        "                max_val = unique_vals.max()\n",
        "                edges = torch.linspace(min_val, max_val, steps=num_bins+1)[1:-1]\n",
        "            else:\n",
        "                quantiles = torch.linspace(0, 1, num_bins + 1)[1:-1]\n",
        "                sorted_feature, _ = torch.sort(feature)\n",
        "                idx = (quantiles * (N - 1)).long().clamp(max=N - 1)\n",
        "                edges = sorted_feature[idx]\n",
        "            bin_edges_list.append(edges)\n",
        "        bin_edges = torch.stack(bin_edges_list, dim=0)\n",
        "        return bin_edges.contiguous()\n",
        "\n",
        "    def preprocess_gpu_data(self, X_np, Y_np, era_id_np):\n",
        "        self.num_samples, self.num_features = X_np.shape\n",
        "        X = torch.from_numpy(X_np).type(torch.int8).to(self.device)\n",
        "        Y_gpu = torch.from_numpy(Y_np).type(torch.float32).to(self.device)\n",
        "        era_id_gpu = torch.from_numpy(era_id_np).type(torch.int32).to(self.device)\n",
        "        bin_edges = self.compute_quantile_bins(X, self.num_bins).type(torch.float32).contiguous()\n",
        "        bin_indices = torch.empty((self.num_samples, self.num_features), dtype=torch.int8)\n",
        "        for f in tqdm(range(self.num_features), desc='Bucketizing...'):\n",
        "            bin_indices[:, f] = torch.bucketize(X[:, f], bin_edges[f], right=False).type(torch.int8)\n",
        "        bin_indices = bin_indices.to(self.device).contiguous()\n",
        "        bin_edges = bin_edges.to(self.device)\n",
        "        unique_eras, era_indices = torch.unique(era_id_gpu, return_inverse=True)\n",
        "        return bin_indices, era_indices, bin_edges, unique_eras, Y_gpu\n",
        "\n",
        "    def compute_histograms(self, bin_indices_sub, gradients):\n",
        "        grad_hist = torch.zeros((self.num_features, self.num_bins), device=self.device, dtype=torch.float32)\n",
        "        hess_hist = torch.zeros((self.num_features, self.num_bins), device=self.device, dtype=torch.float32)\n",
        "        histogram_ext.compute_histogram(\n",
        "            bin_indices_sub.to(torch.int32),\n",
        "            gradients,\n",
        "            grad_hist,\n",
        "            hess_hist,\n",
        "            self.num_bins\n",
        "        )\n",
        "        return grad_hist, hess_hist\n",
        "\n",
        "    def find_best_split(self, gradient_histogram, hessian_histogram):\n",
        "        histogram_ext.compute_split(\n",
        "            gradient_histogram.contiguous(),\n",
        "            hessian_histogram.contiguous(),\n",
        "            self.num_features, self.num_bins,\n",
        "            0.0, 1.0, 1e-6,\n",
        "            self.out_feature,\n",
        "            self.out_bin\n",
        "        )\n",
        "        f = int(self.out_feature[0])\n",
        "        b = int(self.out_bin[0])\n",
        "        return (f, b)\n",
        "\n",
        "    def grow_tree(self, gradient_histogram, hessian_histogram, node_indices, depth):\n",
        "        if depth == self.max_depth:\n",
        "            leaf_value = (self.Y_gpu[node_indices] - self.gradients[node_indices]).mean()\n",
        "            self.gradients[node_indices] += self.learning_rate * leaf_value\n",
        "            return {\"leaf_value\": leaf_value, \"samples\": node_indices.numel()}\n",
        "\n",
        "        best_feature, best_bin = self.find_best_split(gradient_histogram, hessian_histogram)\n",
        "        if best_feature == -1:\n",
        "            leaf_value = (self.Y_gpu[node_indices] - self.gradients[node_indices]).mean()\n",
        "            self.gradients[node_indices] += self.learning_rate * leaf_value\n",
        "            return {\"leaf_value\": leaf_value, \"samples\": node_indices.numel()}\n",
        "\n",
        "        split_mask = self.bin_indices[node_indices, best_feature] <= best_bin\n",
        "        left_indices = node_indices[split_mask]\n",
        "        right_indices = node_indices[~split_mask]\n",
        "        left_size, right_size = left_indices.numel(), right_indices.numel()\n",
        "\n",
        "        if left_size == 0 or right_size == 0:\n",
        "            leaf_value = (self.Y_gpu[node_indices] - self.gradients[node_indices]).mean()\n",
        "            self.gradients[node_indices] += self.learning_rate * leaf_value\n",
        "            return {\"leaf_value\": leaf_value, \"samples\": node_indices.numel()}\n",
        "\n",
        "        if left_size < right_size:\n",
        "            gradient_histogram_left, hessian_histogram_left = self.compute_histograms(self.bin_indices[left_indices], self.residual[left_indices])\n",
        "            gradient_histogram_right = gradient_histogram - gradient_histogram_left\n",
        "            hessian_histogram_right = hessian_histogram - hessian_histogram_left\n",
        "        else:\n",
        "            gradient_histogram_right, hessian_histogram_right = self.compute_histograms(self.bin_indices[right_indices], self.residual[right_indices])\n",
        "            gradient_histogram_left = gradient_histogram - gradient_histogram_right\n",
        "            hessian_histogram_left = hessian_histogram - hessian_histogram_right\n",
        "\n",
        "        new_depth = depth + 1\n",
        "        left_child = self.grow_tree(gradient_histogram_left, hessian_histogram_left, left_indices, new_depth)\n",
        "        right_child = self.grow_tree(gradient_histogram_right, hessian_histogram_right, right_indices, new_depth)\n",
        "\n",
        "        del gradient_histogram\n",
        "        del hessian_histogram\n",
        "\n",
        "        return {\n",
        "            \"feature\": best_feature,\n",
        "            \"bin\": best_bin,\n",
        "            \"left\": left_child,\n",
        "            \"right\": right_child\n",
        "        }\n",
        "\n",
        "    def grow_forest(self):\n",
        "        forest = [{}] * self.n_estimators\n",
        "        for i in tqdm(range(self.n_estimators), desc=\"Growing trees\"):\n",
        "            self.residual = self.Y_gpu - self.gradients\n",
        "            self.root_gradient_histogram, self.root_hessian_histogram = self.compute_histograms(self.bin_indices, self.residual)\n",
        "            tree = self.grow_tree(\n",
        "                self.root_gradient_histogram,\n",
        "                self.root_hessian_histogram,\n",
        "                self.root_node_indices,\n",
        "                depth=0\n",
        "            )\n",
        "            forest[i] = tree\n",
        "        return forest\n",
        "\n",
        "    def flatten_tree(self, tree):\n",
        "        flat_nodes = []\n",
        "        def recurse(node):\n",
        "            idx = len(flat_nodes)\n",
        "            if \"leaf_value\" in node:\n",
        "                flat_nodes.append([1, -1, -1.0, -1, -1, node[\"leaf_value\"]])\n",
        "                return 1\n",
        "            else:\n",
        "                flat_nodes.append([0, node[\"feature\"], float(node[\"bin\"]), -1, -1, -1.0])\n",
        "                left_count = recurse(node[\"left\"])\n",
        "                right_count = recurse(node[\"right\"])\n",
        "                flat_nodes[idx][3] = idx + 1\n",
        "                flat_nodes[idx][4] = idx + 1 + left_count\n",
        "                return 1 + left_count + right_count\n",
        "        recurse(tree)\n",
        "        return torch.tensor(flat_nodes, device=self.device, dtype=torch.float32)\n",
        "\n",
        "    def predict_forest_batch(self, X_batch):\n",
        "        # Instead of looping over trees in Python,\n",
        "        # call the TorchScript _predict_forest that iterates over the list of trees.\n",
        "        flat_forests_ts: List[torch.Tensor] = self.flat_forest\n",
        "        return _predict_forest(flat_forests_ts, X_batch, self.bin_edges, self.max_depth, self.learning_rate, self.base_prediction)\n"
      ],
      "metadata": {
        "id": "Be_LnLC2tgnP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Example usage:\n",
        "# ---------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace 'train', 'feature_set', 'targets', and 'era' with your actual data variables.\n",
        "    X = train[feature_set].values.astype(np.int8)\n",
        "    y = train[targets].values.astype(np.float32) if TRAIN else None\n",
        "    era = train[['era']].values.astype(int) if TRAIN else None\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "fvfoONgUi45u"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN:\n",
        "  model = ErasplitGBDT(num_bins=5,\n",
        "                       max_depth=5,\n",
        "                       learning_rate=0.01,\n",
        "                       n_estimators=2000)\n",
        "  # Train on the entire dataset (full batch training)\n",
        "  model.fit(X, y, era)\n",
        "  torch.save(model, 'model.pth')\n",
        "else:\n",
        "  with torch.serialization.safe_globals([ErasplitGBDT]):\n",
        "    model = torch.load(\"model.pth\", weights_only=False)\n",
        "  preds = model.predict(X)\n",
        "  train['prediction'] = preds\n"
      ],
      "metadata": {
        "id": "gRr7cbb9SJ0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f82fd86-db44-41c8-d369-a41c1867dad4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting batches: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not TRAIN:\n",
        "  train[\"prediction\"] = train['prediction'].rank(pct=True)\n",
        "  train[['prediction']].to_parquet('live.parquet')\n"
      ],
      "metadata": {
        "id": "qacV_xc1zt4L"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[['prediction']]"
      ],
      "metadata": {
        "id": "vuwB8lh40c0j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "ed2e8c6c-1b56-4656-b741-0d6290df7f4b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  prediction\n",
              "id                          \n",
              "n00051870d69760e    0.221368\n",
              "n0010dbaaf8a002c    0.060261\n",
              "n00149a3d96b5e0a    0.164796\n",
              "n0029c4792309ee2    0.789700\n",
              "n003b65d301107cc    0.799078\n",
              "...                      ...\n",
              "nffb9db73af1c9cf    0.978017\n",
              "nffbe447250b5f67    0.795849\n",
              "nffcdf7ca23f25fd    0.732360\n",
              "nffd19077f7fe6cc    0.473636\n",
              "nfff5d29b8f8a878    0.190930\n",
              "\n",
              "[6505 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06be90a6-bfbf-498b-88a2-ead9d0c73e10\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>n00051870d69760e</th>\n",
              "      <td>0.221368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n0010dbaaf8a002c</th>\n",
              "      <td>0.060261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n00149a3d96b5e0a</th>\n",
              "      <td>0.164796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n0029c4792309ee2</th>\n",
              "      <td>0.789700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n003b65d301107cc</th>\n",
              "      <td>0.799078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nffb9db73af1c9cf</th>\n",
              "      <td>0.978017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nffbe447250b5f67</th>\n",
              "      <td>0.795849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nffcdf7ca23f25fd</th>\n",
              "      <td>0.732360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nffd19077f7fe6cc</th>\n",
              "      <td>0.473636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nfff5d29b8f8a878</th>\n",
              "      <td>0.190930</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6505 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06be90a6-bfbf-498b-88a2-ead9d0c73e10')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06be90a6-bfbf-498b-88a2-ead9d0c73e10 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06be90a6-bfbf-498b-88a2-ead9d0c73e10');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-811d9a6f-07a6-4da2-a0e8-3f32fbadb131\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-811d9a6f-07a6-4da2-a0e8-3f32fbadb131')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-811d9a6f-07a6-4da2-a0e8-3f32fbadb131 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train[['prediction']]\",\n  \"rows\": 6505,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6505,\n        \"samples\": [\n          \"nde4977b95015a6d\",\n          \"n7b9de03f0dfcef4\",\n          \"nf6d77e5515781b2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prediction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28869732240312346,\n        \"min\": 0.00015372790161414298,\n        \"max\": 1.0,\n        \"num_unique_values\": 6489,\n        \"samples\": [\n          0.38708685626441197,\n          0.9400461183704842,\n          0.793543428132206\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NghlNh5Rz0pb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}